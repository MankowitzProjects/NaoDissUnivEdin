\chapter{Discussion and Conclusion}
\label{sec:discussionConclusion}

\section{Discussion}
\label{sec:discussion}
%1. Results and success
In this thesis, five feature extraction algorithms have been compared using images captured by a Nao humanoid robot. Two of the algorithms, BRISK0 and BRISK0 - U-BRISK, are variations of the original BRISK implementation \cite{Leutenegger2011}. BRISK0 has also been combined with 2D SURF to create the BRISK0 - SURF2D algorithm. The 1D SURF algorithm has been developed and implemented by the \textit{rUNSWift} team \cite{Anderson}.\\

A novel scoring function termed the \textit{Multi-Image Score} (MIS) has been developed in order to determine the optimal parameters for each  of the BRISK-based feature extraction algorithms. This scoring function determines the optimal parameters based on efficiency, NVMs and IZMs.\\

Using these parameters, all of the BRISK-based feature extraction algorithms as well as 1D SURF were compared in three different environments and BRISK0 - U-BRISK generated the best overall performance. In the worst case, this algorithm can match $67\%$ of the overlapping image pairs whilst maintaining a FP rate of $0$. 1D SURF is an order of magnitude faster but BRISK0 - U-BRISK achieves superior classification performance in all three environments. \\





a novel scoring function has been developed based on computational efficiency, NVMs and IZMs for each of the 

Novel Scoring Function

BRISK0 - U-BRISK selected as the best algorithm

Varying lighting

Different camera sensor

Google Street View

Matching Score as the inverse distance between descirptors in feature space

2-NN Ratio verified.

Developed a matching constraint

Localisation Algorithm



%2. Why hard for others

%3. Essence of innovation
 - Developing a novel score function to find the optimal thresholds for feature extraction algorithms
 - Incorporated variations of BRISK such that it can be used on a Nao
 - Created a localisation algorithm to help the Nao localise for Robocup
 - Tested the algorithm using Nao images with Google Street View.


%Problems and Limitations

It has been found that features such as windows tend to increase the number of interest points that are detected. In addition, fewer interest points are detected on lower resolution features.\\

BRISK0 - U-BRISK was analysed further and it was found that varying the illumination of an environment causes less valid interest point matches to be detected. However, BRISK0 - U-BRISK still detects on average $9.53$ valid matches for overlapping images in the worst case scenario. BRISK0 - U-BRISK is also sensitive to different camera settings and it has been found that matching image pairs from different cameras decreases the performance.\\

Computing the median rather than the max - Outliers

Learning distances to features using vision papers - see email

Valid Matches - Overlapping images tend to produce a large number of matches that are invalid. However, since the images are similar and weak interest points are being detected, it seems plausible that matches will be generated in the same region and all other matches will be filtered out from the constraints. This is because the overlapping regions tend to have similar features???

2-NN Constraints

Similar looking scenes are going to cause a large number of ambiguous matches and reduce the performance.

%Recommendations for future work
Calculate range and bearing to visual landmarks

Implement on the robot

More extensive analysis using Google Street View

Test other methods on Google Street View

Increase the performance of BRISK or SURF



\section{Conclusion}
\label{sec:conclusion}