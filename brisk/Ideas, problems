13/06/2012

1. I could use the ordering of features to remove some invalid matches.
Problem: is that if features are too close together and the image is rotated, then the features will be in a different order 
but they should still be matched correctly
2. It may be possible to find the Euclidean distance to each of the features. 
Problem: If there are invalid matches, then the Euclidean distance will be incorrect for all features
3. Try and transform the image in terms of rotation and scale in order to get it standard. Calculate the projection matrix using
the bank image and the actual image and see good the projection matrix is. If it seems good, then a good match has occurred. 
4. Maybe use response or size in order to detect valid features. Are two matching keypoints the same size/ have similar responses?
5. Remember to implement a KNN matching of 2 points and then check how close those points are to one another

Problems:
1. The SSE2 and SSSE3 instruction sets are not enabled. 
Solution: Add the command -msse2 and -msse4.2 to the relevant buildfiles in the Nao. These are Nao.make.zbuild etc...
Note: -msse3 and -msse4.2 should be added to SimulatedNao.zbuild makefile

17/06/12

1. OpenCV does not compile on bhuman.
Possible Solution: add "opencv/" to both "cv.h" and "highgui.h"

2. Remember that you declare the sub-class first and then the main class if the main
class intends to utilise the sub-class in a header file

3. Problem: The CvPoint is not defined. 
Solution: Remove translateCorners from iPoints. This shouldnt even compile on most
linux distributions


4. There is a Base class from which every module is derived

18/07/12

1. Problem: The debugger does not work. Solution: It seems that you need to start a project with all the files imported into the main project
Remember to set the Debug Configuration to GDB Create Process Launcher. Otherwise CLEAN the project and rebuild. Sometimes may need to make in the terminal after the cleaning has occured.

19/06/12

1. In order to speed up the BRISK algorithm, only use a single octave. This means you won't do a scale-space interpolation, meaning that you may
not find the optimum scale for the image. You have also relaxed the criterion for detecting keypoints as they dont need to be compared to the layers
above and below.

20/06/12

1. When compiling, it may say multiple declarations. This means that there are possibly 2 files that are exactly the same dispersed amongst the 
source code.

21/06/12

1. Cannot use a value from the NaturalLandmarkPercept: "theNaturalLandmarkPercept" in NaturalLandmarkSensorModel" - This was because I didn't update the
name of the percept in the SelfLocator.h class when defining the representations REQUIRES and PROVIDED by the module.

22/06/12

Ideas:
Motivation for using my localisation approach:
1. Using MonoSLAM requires Structure From Motion. You therefore need to consistently estimate the pose. You also need to take an initial snapshot
of the location of the robot from a known distance to the features. This creates a reference frame. My method does not require that technique. - CHECK
2. SFM needs to take a number of frameshots to get depth hypotheses. Even if it gets these hypotheses, these are approximations and may not be 
very accurate.
3. It may also take a larger amount of time as the robot needs to take a number of snapshots in different directions to ensure that it finds a match. This means that far more snapshots are required than simply deciding where the robot has been placed.
4. My method also allows for the robot to be placed on the halfway line on the opponents side of the goal.

Disadvantages of my approach:

1. The assumption is that the robot is always placed facing the opponents goal or on the half-way line.  - FIX: The robot can retry to localise itself,. If that doesn't work, then the robot will turn around and try again.
2. It cannot be placed facing the opponents goal, in the opponents half of the field. - FIX: The robot can use the distance to the opponents goal to determine where he has been placed on the field. This will remove particles that are far away from the opponents goal, or too close to the opponents goal.

24/06/12

Problem: The path is not found when compiling in the terminal. Solution: the path is incorrect. You need an extra '../' This is because you are running this application from the executable which is found in \unix\bin. Thus you have to go back twice, I.e. '../../' in order to reach the images directory.

Problem: The problem with the libraries is something to do with the code I have added. It could possibly be the addition of the build flags -msse2 and -msse4.2 which were added at the end of the file


27/06/12

1. Problem: The python scripts were not executable. This is a permission issue
To add permission to the files, use the command sudo chmod -R 777 /folder_name
Use ls -l in order to view the permissions of all the files

2. Idea: Instead of using the x,y threshold idea, rather remove samples that have different orientations to the current direction that the Nao is facing
3. Run the robot images on the example code to see if depth hypotheses are a possibility
4. Create a behaviour that enables the Nao to turn its head up to the ceiling.


30/07/12

1. Problem:
There has been a persistent problem when using ./copyfiles script to compile the code for the Nao. This uses the makefile, Nao.make.zbuild in order to link the various libraries. The libraries are dynamically linked using the "*.so" extension. 

Solution: In order to include these libraries when compiling, they must be added to the libs section in the makefile as follows:

libs = { 
    "rt", "jpeg-mmx", "protobuf", "pthread", "b-script-geode", "dl", "opencv_core", "opencv_contrib", "opencv_features2d",  "opencv_flann", "opencv_gpu", "opencv_highgui", "opencv_imgproc", "opencv_ml", "opencv_legacy", "opencv_objdetect"
  }

The files are found in the opencv library. Note that the files are called E.g. "libopencv_test". To include it in the makefile, use "opencv_test"

2. Problem:
Certain files are not included in the files section in the Makefiles. This creates the following error:
fatal error: cvWrapper.h: No such file or directory
compilation terminated.

In order to resolve this error, add the folders to search for these files in the "file" section of the Makefile.

3. Problem: It cannot find directories within the src files of the agast library
Solution: Add the terms "../include/agast/" to the files "cvWrapper.h" and "xxx.h"

Note: IncludePaths in the Makefile only includes libraries with .h extension. IncludeLibs includes libraries with the .so extension

Compiles with nao.make.zbuild
********************************************************************

Fix problem of SimRobot:
********************************************************************
1. Problem: Cannot load library /home/daniel/Desktop/RoboCupCode/BhumanEdinferno/ehuman/Build/SimRobot/Linux/Develop/libRoboCup.so: (/home/daniel/Desktop/RoboCupCode/BhumanEdinferno/ehuman/Build/SimRobot/Linux/Develop/libRoboCup.so: undefined symbol: _ZTVN5agast16AgastDetector5_8E)

The previous problem was fixed by adding: 
matchrecursive("../../Src/Tools/ImageProcessing/brisk.cpp", "../../Src/Tools/ImageProcessing/DataAnalysis.cpp", "../../Src/Tools/ImageProcessing/FeatureExtraction.cpp", "../../Src/Tools/ImageProcessing/include/*.h"),
matchrecursive("../../Src/Tools/ImageProcessing/agast/*.cc", "../../Src/Tools/ImageProcessing/agast/*.h"),

to the SimRobot.make.zbuild file.
Now we have to remove the above-mentioned error.

Solution:
To fix this problem, add:
    matchrecursive("../../Src/Tools/ImageProcessing/brisk.cpp", "../../Src/Tools/ImageProcessing/DataAnalysis.cpp", "../../Src/Tools/ImageProcessing/FeatureExtraction.cpp", "../../Src/Tools/ImageProcessing/include/*.h", "../../Src/Tools/ImageProcessing/include/*.hpp"),
    matchrecursive("../../Src/Tools/ImageProcessing/agast/src/*.cc", "../../Src/Tools/ImageProcessing/agast/include/agast/*.h"),  
to the "files" section

THEN add:

    "/home/daniel/Desktop/OpenCV-2.2.0/include", to "includePaths"

THEN add:
"/home/daniel/Desktop/OpenCV-2.2.0/lib", to "libPaths"

THEN add:
"opencv_core", "opencv_contrib", "opencv_features2d",  "opencv_flann", "opencv_gpu", "opencv_highgui", "opencv_imgproc", "opencv_ml", "opencv_legacy", "opencv_objdetect" to libraries


04/07/12

1. Question: What is the difference between setting the number of octaves to 0 on BRISK and using BRISK with S-BRISK?

Testing:
To do the BRISK BRISK test with Hamming distance and thresholds, Hamming must be true.


11/07/12
To do BRISK SURF tests hamming must be false



12/07/12
//**************************ANALYSIS**************************************************

The factors in these thresholds are:
1. Time(0.6)
2. The number of valid matches/totalmatches (for its individual match) (0.4)
3. The number of Zero matches (0.6)


KNN -  Hamming/Euclidean distance
1. Has lower thresholds  - Has higher thresholds . Has large hamming distance therefore accepts more matches
2. Detects more keypoints due to low threshold - Detects less keypoints due to high threshold


SBRISK - BRISK4

1. Should detect more keypoints and does so compared to BRISK4 - Detects less keypoints



UBRISK - 

1. Detects less keypoints as it is set to a higher threshold. Since rotation invariance has been removed, 
it has been given a higher threshold as it detects a sufficient amount of keypoints

SBRISK - SURF2D


Low Threshold

1. More points are detected.
2. The run-time is slower.
3. Reduces the number of NZMs.
4. Can increase the number of valid matches (will find weaker matches that may be valid)

High Threshold
1. Less points are detected. (Or can detect a sufficient amount of points at this value)
2. faster
3. Increases the number of NZMs
4. Reduces the number of valid matches

Higher hamming distance
1. More matches are accepted. Therefore weaker matches are utilised.
2. Decreases the number of zero matches

Lower hamming distance
1. Less matches are accepted. Less are therefore validated.
2. Decreases the number of zero matches

KNN
****************************************
SBRISK - SBRISK
1. detects 77 keypoints and has an adequate number of matches at a threshold of 46.25. (These matches may not be very good
since they are only detected along a single scale). This could result in a large number of zero matches. It has 20% which implies that
it should have a relatively large threshold. 

2. Is very fast, so can operate at a lower threshold. This will ensure that it can detect more valid keypoints and less non zero matches

3. There may be a large amount of invalid matches due to the weak detection criteria, but there may also be weak
matches that are indeed valid that are found as well at a lower threshold.


BRISK4
1. It should have less keypoints (or have a lower threshold than the rest to ensure that keypoints are selected). 
2. It does have a much larger detection time, more than double the others which results in the higher threshold. This is because
time has been given the most weight in the optimisation routine.


BRISK0 SURF2D

1. Operates at the lowest threshold (meaning it detects more keypoints than the others.) 
2. It has a much larger extraction time as it needs to match using euclidean distance which takes alot longer than the hamming criteria.
3. Detects the largest number of valid matches but its ration of valid matches/total matches is low

BRISK0 UBRISK
1. Operates at the highest threshold. This is probably because it is the fastest of all the methods. Thus it can add more
weight to detecting more valid matches and therefore less non zero matches.


*******************************************
 












