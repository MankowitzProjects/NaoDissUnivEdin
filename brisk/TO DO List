13/06/2012

TO DO:

1. Add the method for detecting invalid features based on the ordering constraint. **
2. Incorporate OpenSurf into the code (Removing the dependance on OpenCV from SURF descriptor's perspective. **
3. Test BRISK BRISK - Sent email, awaiting reply - DONE
4. Compare times, accuracy for SURF, BRISK, SIFT etc.
5. Look at reducing the run-time of the code, by modifying SURF descriptor.
6. Try and compile the code on the Nao ** - In Process
7. Adapt the formula in determining the optimal radius and threshold to take weights into account. **
8. Look at Benji's idea of invariant scale and rotation.

//Tests to perform
1. Once the new weighting formula has been found, re-run the matching tests.
2. Create a test to find the difference in size between each of the keypoints
3. Create a test to find the length (xdist, ydist and euclidean) between each of the keypoints

17/06/12

1. A routine needs to be created whereby the robot compares its received image to a bank of test images
 - The robot needs to take the current image and match it with the other images. 
 - The image with the closest match will be the one that the robot chooses. 
2. A routine needs to be developed that takes images with the robot before the match begins such that it can
store images in the image bank.

//The code
1. Find the point where the image is created and pass the image through to the image processing step (For now, just create an image object)
2. In the image processing step, perform the matching routine and pass the number of matches to the LandmarkPerceptOR
3. Once the matches have been found, update the matchedKeypoints and send them through to the NaturalLandmarkSensorModel

//The Feature Extraction
1. Convert the 2D SURF to the 1D SURF implementation that has been implemented by the RUNSwift team.


18/06/12

1. Review OpenCV IplImage. Read in theImage in bhuman code. -DONE
2. Review and understand the YUV422 image structure and determine how to convert it to Grayscale -DONE 


19/06/12

1. Add in the edit distance algorithm to add an ordering constraint into nearest neighbors. SAME - Add the feature matching criteria that takes the order of the features into account (Cannot be done as not robust enough)
2. Determine if there are ways to speed up the BRISK Detection process - DONE (Create a single octave)
3. Add the feature matching criteria that gets the 2 KNN and then determines the distance between the matches - DONE (Created the distance ratio)

20/06/12

1. Incorporate the BRISK BRISK method into the Bhuman Codebase - DONE
2. Try and implement the reweighting routine. - DONE (To be tested)
3. Find a way to determine the angles to the features (For both 1D SURF and BRISK) (PROBABLY NOT NEEDED as you can use heuristics)

21/06/12

1. The weightings have been added to the code. The next step is to add the robots head turning routine when it enters the field.
2. In addition, the routine to take the images at the start of the game needs to be implemented
3. I need some way to turn the robot's head and get the robot's head angle. (HeadMotionRequest perhaps?) - I may need to create a new behaviour. (That information is from the camera matrix. Gives the robots coordinates and you can determine its relative position)
4. I also need to get the Grayscale image from the code - DONE (But not very efficient. I should try and take the pixels above the horizon into account.) - DONE except for the openSURF implementation. I need to find a way to extract a sub-region of an IplImage to be used for further processing


25/06/12

TESTS
***************************
1. We need to determine the performance under different rotations, scales, translations, occlusions
2. Determine the repeatability (find definition) of the feature extractor under changing angles, scale, blur.
3. Compare BRISK-BRISK, BRISK BRISK(NO SCALE SPACE), BRISK SURF, BRISK USURF, SIFT SIFT, 1D SURF etc
4. Compute the mean distance between features over a number of images. E.g. take a number of keypoints from 20 images and compute their mean distances
5. Compute the distance ratio between features that are matches and features that are not matches


***************************
1. Setup a file that is able to calculate a number of properties for a single image. I.e. keypoint distance, scale, response, size, matches etc... 

#The general image properties can be calculated for both properties

The image properties are

image num, keypoint x, keypoint y, angle, size, octave, response

#This is calculated for the single image

The matching properties are:

image num left, image num right, queryIdx, trainIdx,  keypoint1 x, kp1y, angle size, octave, response, kp2x, kp2y, angle, size, octave, neighbor num, distance

Writing invalid matches to a files

image num left, image num right, kp1x, kp1y, angle, size, octave, response, kp2x, kp2y, angle, size, octave, neighbor num, distance 

28/06/12

1. make OpenCV, port it to the SDK - DONE
2. Include the relevant files into the bhuman framework - DONE
3. Hope for the best :)

03/07/12

1. Include invalid matches using KNN routine and angle constraint routine - This should be written to files
2. Need to determine the mean number of features that are found for the particular threshold

TESTS
***********************************



3. Note that the reason the kNN criterion works is that two matches that are very close to
one another can potentially be attributed to noise

04/07/12

Format for saving data

 - For finding the optimal threshold

threshold_detector_extractor_matcher(KNN or radius)_ddmmyyhhmm.txt

 - For finding the matching statistics

nonmatching_matching_data_detector_extractor_matcher_ddmmyyhhmm_threshold1_threshold2_...txt

 - For single image statistics

single_image_data_detector_extractor_matcher_ddmmyyhhmm_threhsold1_threshold2_...txt


ROC Curve and Timing Tests
******************************************************************
1. Run S-BRISK KNN at an angle of 10. - DONE
2. Run S-BRISK Hamming (on 10 images) at an angle of 10. - DONE

3. Run BRISK4 KNN at an angle of 10. - DONE
4. Run BRISK4 Hamming (on 10 images) at an angle of 10 - DONE

5. Run SBRISK SURF2D KNN at an angle of 10. - DONE
6. Run SBRISK SURF2D Hamming (on 10 images) at an angle of 10. - DONE

7. Run SURF2D SURF2D KNN at an angle of 10.
8. Run SURF2D SURF2D Hamming (on 10 images) at an angle of 10.

9. Run BRISK4 SURF2D KNN at an angle of 10.
10. Run BRISK4 SURF2D Hamming (on 10 images) at an angle of 10.

11. Run SURF1D KNN at an angle of 10.
12. Run SURF1D Hamming (on 10 images) at an angle of 10.

*****************************************************************

Single Image Tests
*****************************************************************
1. Compute the score for matches and the score for false matches (Don't fulfill KNN or angle criterion). - DONE
2. Compute the average size of keypoint matches, angle, octave (Where applicable). - DONE
3. Calculate the average image matching score for overlapping and non-overlapping images - DONE

Issues:
1. I need to test all the hamming tests on all of the images or rerun the KNN tests on 10 images - DONE
1.1 The matching scores for KNN may be incorrect as one extra match is saved each time. This means KNN tests should be repeated - DONE
2. I should compare whether averaging the mScores and then finding the threshold is better than finding the max thresholds
and averaging - DONE
3. I need to setup the implementation for the single image comparison tests. I need to find the distance between keypoints. Possibly
could create a distance vector whose index corresponds to the keypoint - DONE

05/07/12

1. Determine how many image pairs are being compared for matches and non matches - DONE

09/07/12

1. The mean extraction time is the time it takes for a SINGLE image to extract features and
compute the descriptors. - DONE

Note:

1. There is a bias in the mean time as more weight is being given to images that appear more
frequently in the comparisons.
Solution: To go through every combination of images (with repitition) and compute the mean time.
This will cause each image to be extracted from an equal number of times.

2. Accurate matching times will then be distorted. These times should only be computed from
the combinations of images w/o repitition.

3. The threshold times are biased for the mean extraction and detection times.

4. We should only calculate the detection time for a single detector since we will be given
a descriptor on the Nao. Similarly for the calculation of the descriptor. Only the matching time is
important.


10/07/12

1. I must re-run all the tests on the new thresholds with the new times.
2. I must test single image comparison tests on more methods.
3. I must remember to incorporate U-BRISK into the testing procedure - DONE
4. I must implemenet correct averaging of time - DONE
5. Consider the minimax (The maximum, minimum value) (Could be a better score function)
6. Consider doing a score of maximum weightings
7. Determine if the points are metrics

Writing
1. I must document the methods used for angle constraints and KNN constraint
e2. I must document my changes to 1D SURF and BRISK (SBRISK, UBRISK).
3. Document the results

Tests:
***************************************************
1. Run S-BRISK KNN at an angle of 10. - DONE
2. Run S-BRISK Hamming at an angle of 10. 

3. Run BRISK4 KNN at an angle of 10. - DONE
4. Run BRISK4 Hamming at an angle of 10 

5. Run SBRISK SURF2D KNN at an angle of 10. - DONE 
6. Run SBRISK SURF2D Hamming at an angle of 10

7. Run SURF2D SURF2D KNN at an angle of 10.
8. Run SURF2D SURF2D Hamming at an angle of 10.

9. Run BRISK4 SURF2D KNN at an angle of 10. 
10. Run BRISK4 SURF2D Hamming at an angle of 10.

11. Run SURF1D KNN at an angle of 10.
12. Run SURF1D Hamming at an angle of 10.

13. Run SBRISK - U-BRISK KNN at an angle of 10. - DONE
14. Run SBRISK - U-BRISK Hamming at an angle of 10.

Note:
1. The Best Matching score is used to calculate the classification boundary because we can't compare Hamming and KNN.
Hamming may have 5 different matches whereas KNN always has 2. Thus cannot compare general because then 2 methods are
not comparable.

11/07/12

1. Determine how many keypoints on average for each method.
2. Determine how many matches on average for each method.

Match - Stores the qIDx, tIdx, ImgIdx and the distance between the two keypoints. 

Match (1,1)

The first match

std::sort - sorts the elements in the rand (first, last) in ascending order

rbegin - returns a reverse iterator to the last element in the vector container

Therefore in matches, since matches is a vector of vectors, rbegin goes to the last element in the
vector container. That is the latest vector of DMatches that has been added to Match

Note: To record KNN features and angles, turn SINGLE_IMAGE_COMPARISONS on

14/07/12

1. Get KNN and hamming distance results on the new dataset - DONE for KNN
2. Get hamming distance comparisons on new dataset 
3. Add pictures - partly
4. Add angle constraints description and KNN description

15/07/12

Nao to do:
1. Get code to compile.
2. make sure I understand STREAM
3. Understand DEBUG


18/07/12

*********************POSSIBLE TESTS******************************
1. Put occlusions in front of the photos to represent humans during robocup
2. Take pictures with my phone or camera and compare them with the robot pics.


22/07/12

************************TESTS************************************
1. Large Hall Dataset

Classification

KNN Values (Max/Consistent)

BRISK0 - DONE
SURF2D - DONE
BRISK4 - DONE
BRISK0-U-BRISK - DONE
SURF 1D - DONE

Hamming/Euclidean

BRISK0 - DONE
SURF2D - DONE
BRISK4 - DONE
BRISK0-U-BRISK - DONE
SURF 1D - DONE

2. Office

Classification

KNN (max and consistent) 

BRISK0 - DONE
SURF2D - DONE
BRISK4 - DONE
BRISK0-U-BRISK - DONE
SURF 1D - DONE

Hamming/Euclidean

BRISK0 - DONE
SURF2D - DONE
BRISK4 - DONE
BRISK0-U-BRISK - DONE
SURF 1D - DONE

3. Overall Performance

SURF1D KNN - DONE

SURF 1D Hamming - DONE

4. Fix up the mean number of keypoints  - Not yet achieved

24/07/12

1. Take pictures with phone camera of the atrium and the robocup internal arena.

2. Tomorrow, take the Nao outside and take pictures of George Square and a place that uses Google Street View

3. Run the comparison tests to see how well the systems match
